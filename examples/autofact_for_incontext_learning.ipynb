{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUdk_Tc0rfma",
    "outputId": "a8b5b995-3575-41c0-cc02-a62669136352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==0.24.2 in /usr/local/lib/python3.7/dist-packages (0.24.2)\n",
      "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
      "Requirement already satisfied: transformers==4.8.2 in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
      "Requirement already satisfied: PyAutoFact==0.1.17 in /usr/local/lib/python3.7/dist-packages (0.1.17)\n",
      "Requirement already satisfied: datasets==1.10.2 in /usr/local/lib/python3.7/dist-packages (1.10.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (1.19.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.2) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (3.0.12)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (3.13)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (0.10.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (21.0)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (0.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (4.6.4)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (0.0.45)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.8.2) (4.62.0)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from PyAutoFact==0.1.17) (0.0)\n",
      "Requirement already satisfied: matplotlib==3.4.2 in /usr/local/lib/python3.7/dist-packages (from PyAutoFact==0.1.17) (3.4.2)\n",
      "Requirement already satisfied: matrix-fact==1.1.2 in /usr/local/lib/python3.7/dist-packages (from PyAutoFact==0.1.17) (1.1.2)\n",
      "Requirement already satisfied: cvxopt==1.2.6 in /usr/local/lib/python3.7/dist-packages (from PyAutoFact==0.1.17) (1.2.6)\n",
      "Requirement already satisfied: seaborn==0.11.1 in /usr/local/lib/python3.7/dist-packages (from PyAutoFact==0.1.17) (0.11.1)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.2) (2021.8.1)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.2) (0.3.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.2) (3.0.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.2) (0.70.12.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.2) (2.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.10.2) (1.1.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.2->PyAutoFact==0.1.17) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.2->PyAutoFact==0.1.17) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.2->PyAutoFact==0.1.17) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.2->PyAutoFact==0.1.17) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.4.2->PyAutoFact==0.1.17) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib==3.4.2->PyAutoFact==0.1.17) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.10.2) (2018.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.8.2) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.8.2) (3.5.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.8.2) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==0.24.2 torch==1.9.0 transformers==4.8.2 PyAutoFact==0.1.17 datasets==1.10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "irDtkCTRoEsq"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from itertools import chain\n",
    "import datasets\n",
    "import random\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Config, GPT2Tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from py_auto_fact import auto_fact\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "21kHt1zhoEsu"
   },
   "outputs": [],
   "source": [
    "def count_param(module, trainable=False):\n",
    "    if trainable:\n",
    "        return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in module.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZB73YAKHoEsu"
   },
   "source": [
    "# Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LCxKGIDdoEsw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TC0lHWj9oEsw",
    "outputId": "e8f0cb83-0a67-49a7-b424-445bf9aafdc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774030080"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_param(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTH05INooEsx"
   },
   "source": [
    "# Apply partial factorization to GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sU2IlPPnoEs3"
   },
   "outputs": [],
   "source": [
    "# Only factorize last one-third of transformer layers of the GPT2 model\n",
    "factorizable_submodules = list(model.transformer.h[-(model.config.n_layer // 3):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jAZM9zeCoEs4",
    "outputId": "f21873a7-c3aa-49e7-b6c4-a68f290f4705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 5.38 s, total: 2min 36s\n",
      "Wall time: 17.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "632472320"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "fact_model = auto_fact(model, rank=384, deepcopy=True, solver='svd', num_iter=20, submodules=factorizable_submodules)\n",
    "count_param(fact_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ourbO-iboEs5"
   },
   "source": [
    "# Speed test on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7wxi3MLoEs5"
   },
   "source": [
    "### Test Inference CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqIT0UmBoEs5",
    "outputId": "043b6faa-4e21-47e4-9d95-0f785cf89288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252 ms ± 407 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    y = model(torch.zeros(2, 64, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FwdLhopoEs5",
    "outputId": "fae6f754-7ad9-4461-b195-68d64dc69267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220 ms ± 598 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    y = fact_model(torch.zeros(2, 64, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opyx5tzEoEs7"
   },
   "source": [
    "# Speed test on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrX66ktEoEs7"
   },
   "source": [
    "### Move models to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xXMU0XVjoEs7"
   },
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "fact_model = fact_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuNlNzSBoEs7"
   },
   "source": [
    "### Test Inference GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "f-HvOx43oEs7"
   },
   "outputs": [],
   "source": [
    "x = torch.zeros(2,64, dtype=torch.long).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvyKZNgPoEs7",
    "outputId": "9cd2961b-3903-4a63-954b-6f7beb04a2e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.2 ms ± 6.54 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybQQZDLkoEs8",
    "outputId": "fc4be74c-4e96-4390-b4e1-719dae031d33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.5 ms ± 30.4 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    y = fact_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-tuFs5xJ6bK"
   },
   "source": [
    "# Prepare Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pIHbY12pe-wa"
   },
   "outputs": [],
   "source": [
    "class SSTDataset(Dataset):\n",
    "    # Static constant variable\n",
    "    NUM_LABELS = 2\n",
    "\n",
    "    def __init__(self, data_split, exp_args, *args, **kwargs):\n",
    "        self.data_split = data_split\n",
    "        self.exp_args = exp_args\n",
    "\n",
    "        if data_split == 'train':\n",
    "            self.dataset = datasets.load_dataset('sst')['train']\n",
    "        elif data_split == 'validation':\n",
    "            self.dataset = datasets.load_dataset('sst')['validation']\n",
    "        elif data_split == 'test':\n",
    "            self.dataset = datasets.load_dataset('sst')['test']\n",
    "        else:\n",
    "            raise ValueError(f'Invalid dataset split: `{data_split}`')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = np.round(self.dataset[index]['label'])\n",
    "        text = self.dataset[index]['sentence']\n",
    "        return text, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oNZsrYm3oEs9"
   },
   "outputs": [],
   "source": [
    "def generate_prompt(texts_by_labels, labels, test_samples):\n",
    "    prompts = []\n",
    "    for label_1 in labels:\n",
    "        pos_samples = texts_by_labels[label_1]\n",
    "        neg_samples = []\n",
    "        prefix = \"\"        \n",
    "        for label_2 in labels:\n",
    "            if label_1 != label_2:\n",
    "                neg_samples = neg_samples + texts_by_labels[label_2]\n",
    "\n",
    "        all_samples = pos_samples + neg_samples\n",
    "        random.shuffle(all_samples)\n",
    "\n",
    "        for sample in all_samples:\n",
    "            text, label = sample[\"text\"], sample[\"label\"]\n",
    "            if label != label_1:\n",
    "                prefix = prefix + text + \"=>\" + label_1 + \"=false\\n\"\n",
    "            else:\n",
    "                prefix = prefix + text + \"=>\" + label_1 + \"=true\\n\"\n",
    "        prompts.append([prefix, label_1])\n",
    "    \n",
    "    few_shot_prompts = []\n",
    "    for sample in test_samples:\n",
    "        prompt_per_label = []\n",
    "        for prompt in prompts:\n",
    "            prefix, label = prompt\n",
    "            new_prompt = prefix + sample[\"text\"] + \"=>\" + label + \"=\"\n",
    "            prompt_per_label.append(new_prompt)\n",
    "        few_shot_prompts.append(prompt_per_label)\n",
    "\n",
    "    return few_shot_prompts\n",
    "\n",
    "def generate_sst_dataset(k_shot):\n",
    "    texts_by_labels = {}\n",
    "    IDX_TO_LABELS = {}\n",
    "\n",
    "    train_dataset = SSTDataset('train', None)\n",
    "    test_dataset = SSTDataset('test', None)\n",
    "\n",
    "    IDX_TO_LABELS = {0: \"negative\", 1: \"positive\"}\n",
    "    for i in range(len(train_dataset)):\n",
    "        text, label = train_dataset[i]\n",
    "        if IDX_TO_LABELS[label] not in texts_by_labels:\n",
    "            texts_by_labels[IDX_TO_LABELS[label]] = []\n",
    "        texts_by_labels[IDX_TO_LABELS[label]].append({\"text\":text, \"label\":IDX_TO_LABELS[label]})\n",
    "\n",
    "    test_samples = []\n",
    "    for i in range(len(test_dataset)):\n",
    "        text, label = test_dataset[i]\n",
    "        test_samples.append({\"text\":text, \"label\":IDX_TO_LABELS[label]})\n",
    "\n",
    "    for label in texts_by_labels:\n",
    "        random.shuffle(texts_by_labels[label])\n",
    "    targets = [\"negative\", \"positive\"]\n",
    "    \n",
    "    for label in texts_by_labels:\n",
    "        texts_by_labels[label] = texts_by_labels[label][:k_shot]\n",
    "\n",
    "    few_shot_samples = generate_prompt(texts_by_labels, targets, test_samples)\n",
    "    return few_shot_samples, test_samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01jhp1ddupl4",
    "outputId": "72d60082-2189-4443-cada-2403eb026691"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: sst/default\n",
      "Reusing dataset sst (/home/samuel/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n",
      "No config specified, defaulting to: sst/default\n",
      "Reusing dataset sst (/home/samuel/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
     ]
    }
   ],
   "source": [
    "few_shot_samples, test_samples, targets = generate_sst_dataset(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0QTp8ViLJhH"
   },
   "source": [
    "# Run In-Context Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tmGI8RBxhSaL"
   },
   "outputs": [],
   "source": [
    "def score_next(model, tokenizer, encoded, token):\n",
    "    with torch.no_grad():\n",
    "        # print(encoded.size(), token.size())\n",
    "        outputs = model(encoded)\n",
    "        next_token_logits = outputs.logits\n",
    "\n",
    "        def _log_softmax(x):\n",
    "            maxval = np.max(x)\n",
    "            logsum = np.log(np.sum(np.exp(x - maxval)))\n",
    "            return x - maxval - logsum\n",
    "\n",
    "        next_token_logits = next_token_logits[:,-1].squeeze()\n",
    "        # print(next_token_logits.size())\n",
    "        scores = _log_softmax(next_token_logits.cpu().detach().numpy())\n",
    "        del next_token_logits\n",
    "        return scores[int(token)]\n",
    "\n",
    "def argmax(array):\n",
    "    \"\"\"argmax with deterministic pseudorandom tie breaking.\"\"\"\n",
    "    max_indices = np.arange(len(array))[array == np.max(array)]\n",
    "    idx = int(hashlib.sha256(np.asarray(array).tobytes()).hexdigest(),16) % len(max_indices)\n",
    "    return max_indices[idx]\n",
    "\n",
    "def logsumexp(x):\n",
    "    c = x.max()\n",
    "    return c + np.log(np.sum(np.exp(x - c)))\n",
    "\n",
    "def normalize(x):\n",
    "    x = np.array(x)\n",
    "    return np.exp(x - logsumexp(x))\n",
    "\n",
    "def calculate_log_prob_gpt(model, tokenizer, prefix, targets):\n",
    "    label2id = {}\n",
    "    for target in targets:\n",
    "        # works for single token label e.g., true or false, yes or no\n",
    "        # label2id[target] = tokenizer.convert_tokens_to_ids(target)\n",
    "        label2id[target] = tokenizer(target, truncation=True)[\"input_ids\"][0] # only take the first token\n",
    "\n",
    "    tokenized = tokenizer(list([prefix]), truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = tokenized.input_ids\n",
    "    attention_mask = tokenized.attention_mask\n",
    "    \n",
    "    input_ids = input_ids.cuda()\n",
    "    attention_mask = attention_mask.cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits.squeeze()[-1]\n",
    "        prob = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        prob = prob.cpu().detach().numpy()\n",
    "    normalized_scores = []\n",
    "\n",
    "    for c in targets:\n",
    "        score = prob[label2id[c]]\n",
    "        normalized_scores.append(score)\n",
    "\n",
    "    pred = targets[argmax(normalized_scores)]\n",
    "    return pred, np.array(normalized_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "d0immqYzLJ6T",
    "outputId": "d97e39e8-83ac-4012-9bfe-8ca271c46c14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 2210/2210 [16:30<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL SCORE | ACC: 63.98190045248868 F1: 60.091651542649736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "golds, preds = [], []\n",
    "pbar = tqdm(iter(few_shot_samples), leave=True, total=len(few_shot_samples))\n",
    "for id, batch in enumerate(pbar):\n",
    "    prompts = few_shot_samples[id]\n",
    "    test_sample = test_samples[id]\n",
    "    all_scores = []\n",
    "    for prompt in prompts:\n",
    "        pred, normalized_scores = calculate_log_prob_gpt(model, tokenizer, prompt, [\"true\", \"false\"])\n",
    "        all_scores.append(normalized_scores)\n",
    "\n",
    "    highest_score_idx = 0\n",
    "    highest_score = 0\n",
    "    for k in range(len(all_scores)):\n",
    "        if all_scores[k][0] > highest_score:\n",
    "            highest_score = all_scores[k][0]\n",
    "            highest_score_idx = k\n",
    "\n",
    "    pred = targets[highest_score_idx]\n",
    "    gold = test_samples[id][\"label\"]\n",
    "\n",
    "    golds.append(gold)\n",
    "    preds.append(pred)\n",
    "\n",
    "acc = accuracy_score(preds, golds) * 100\n",
    "f1 = f1_score(golds, preds, average='macro') * 100\n",
    "print(f\"EVAL SCORE | ACC: {acc} F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pl7GQbMvLKOn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 2210/2210 [15:10<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL SCORE | ACC: 68.68778280542986 F1: 66.80748287980441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "golds, preds = [], []\n",
    "pbar = tqdm(iter(few_shot_samples), leave=True, total=len(few_shot_samples))\n",
    "for id, batch in enumerate(pbar):\n",
    "    prompts = few_shot_samples[id]\n",
    "    test_sample = test_samples[id]\n",
    "    all_scores = []\n",
    "    for prompt in prompts:\n",
    "        pred, normalized_scores = calculate_log_prob_gpt(fact_model, tokenizer, prompt, [\"true\", \"false\"])\n",
    "        all_scores.append(normalized_scores)\n",
    "\n",
    "    highest_score_idx = 0\n",
    "    highest_score = 0\n",
    "    for k in range(len(all_scores)):\n",
    "        if all_scores[k][0] > highest_score:\n",
    "            highest_score = all_scores[k][0]\n",
    "            highest_score_idx = k\n",
    "\n",
    "    pred = targets[highest_score_idx]\n",
    "    gold = test_samples[id][\"label\"]\n",
    "    \n",
    "    golds.append(gold)\n",
    "    preds.append(pred)\n",
    "\n",
    "acc = accuracy_score(preds, golds) * 100\n",
    "f1 = f1_score(golds, preds, average='macro') * 100\n",
    "print(f\"EVAL SCORE | ACC: {acc} F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autofact_for_incontext_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_deep_fact",
   "language": "python",
   "name": "env_deep_fact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
