{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "d162b3b0",
    "papermill": {
     "duration": 6.977078,
     "end_time": "2021-08-19T03:10:46.527438",
     "exception": false,
     "start_time": "2021-08-19T03:10:39.550360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import models, transforms\n",
    "from greenformer import auto_fact\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f18e95be",
    "papermill": {
     "duration": 0.033416,
     "end_time": "2021-08-19T03:10:46.625796",
     "exception": false,
     "start_time": "2021-08-19T03:10:46.592380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_param(module, trainable=False):\n",
    "    if trainable:\n",
    "        return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in module.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86542488",
    "papermill": {
     "duration": 0.012529,
     "end_time": "2021-08-19T03:10:46.652746",
     "exception": false,
     "start_time": "2021-08-19T03:10:46.640217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DxaP1LDf8aT0"
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, model, latent_features, out_features):\n",
    "        super().__init__()\n",
    "        self.latent_features = latent_features\n",
    "        self.out_features = out_features\n",
    "        self.model = nn.Sequential(model, nn.Linear(latent_features, out_features))\n",
    "\n",
    "    def forward(self, inputs, labels=None, *args, **kwargs):\n",
    "        if inputs.shape[1] == 1:\n",
    "            inputs = inputs.repeat(1, 3, 1, 1)\n",
    "\n",
    "        logits = self.model(inputs)\n",
    "\n",
    "        outputs = (logits,)\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.out_features), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e600a31b",
    "papermill": {
     "duration": 6.459678,
     "end_time": "2021-08-19T03:10:53.124136",
     "exception": false,
     "start_time": "2021-08-19T03:10:46.664458",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_module = models.resnext50_32x4d(pretrained=True)\n",
    "cnn_module.fc = nn.Dropout2d(0.1)\n",
    "model = CNNModel(cnn_module, latent_features=2048, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4af037fe",
    "outputId": "458646fe-0375-4494-bda2-1bfec2b83928",
    "papermill": {
     "duration": 0.020808,
     "end_time": "2021-08-19T03:10:53.363394",
     "exception": false,
     "start_time": "2021-08-19T03:10:53.342586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23000394"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_param(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7778691",
    "papermill": {
     "duration": 0.025624,
     "end_time": "2021-08-19T03:10:53.328728",
     "exception": false,
     "start_time": "2021-08-19T03:10:53.303104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Apply Factorization-by-design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0bd9042",
    "outputId": "bb4a4abe-50e0-4dcf-c423-7530d1ae3080",
    "papermill": {
     "duration": 0.384408,
     "end_time": "2021-08-19T03:11:57.041457",
     "exception": false,
     "start_time": "2021-08-19T03:11:56.657049",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12889418\n",
      "CPU times: user 1.87 s, sys: 24 ms, total: 1.89 s\n",
      "Wall time: 285 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/envs/deep_fact/lib/python3.8/site-packages/PyAutoFact-0.1.17-py3.8.egg/py_auto_fact/auto_fact.py:163: UserWarning: skipping convolution with in: 512, out: 16, rank: 32\n",
      "/home/samuel/anaconda3/envs/deep_fact/lib/python3.8/site-packages/PyAutoFact-0.1.17-py3.8.egg/py_auto_fact/auto_fact.py:163: UserWarning: skipping convolution with in: 1024, out: 32, rank: 32\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "factorized_submodules = [model.model[0].layer3, model.model[0].layer4]\n",
    "fact_model = auto_fact(model, rank=0.5, deepcopy=True, solver='random', num_iter=20, submodules=factorized_submodules)\n",
    "print(count_param(fact_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f0708d8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Speed test on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c07d58d",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Test Inference CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1208fe69",
    "outputId": "2c06ab9b-bc92-4f06-e9ef-7dbc0362302f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/envs/deep_fact/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364 ms ± 143 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    y = model(torch.zeros(8,3,224,224, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6b259c9",
    "outputId": "a777dcd6-c03f-4b85-dce8-d91999a6ac32",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293 ms ± 44.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    y = fact_model(torch.zeros(8,3,224,224, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1b2ecc8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Test Forward-Backward CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6879857b",
    "outputId": "beb85052-c717-44e3-a8cf-817cd8390ff4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.76 s ± 81.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "y = model(torch.zeros(8,3,224,224, dtype=torch.float))\n",
    "y[0].sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5542989f",
    "outputId": "3e6e534f-957b-4832-ec28-9e8dba742696",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 s ± 95.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "y = fact_model(torch.zeros(8,3,224,224, dtype=torch.float))\n",
    "y[0].sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e16972f4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Speed test on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b215519d",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Move models to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "336c3460",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "fact_model = fact_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa392662",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Test Inference GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "92bf9f87",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.zeros(64,3,224,224, dtype=torch.float).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ceee0353",
    "outputId": "cef14a52-4069-4606-8dd7-cb5cc895a8f2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 13.47 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "148 ms ± 55 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14a17a90",
    "outputId": "88e654ad-4c1c-4282-eb9e-e35ff594daa4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 ms ± 224 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    y = fact_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0abaddd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Test Forward-Backward GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8755a68e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.zeros(64,3,224,224, dtype=torch.float).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddeed102",
    "outputId": "c866bac3-e308-4167-f4e1-2c3bcf308bc5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656 ms ± 3.37 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "y = model(x)\n",
    "y[0].sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa850456",
    "outputId": "a4bd5f8c-ca78-4a44-b675-3a3c6ad555cb",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631 ms ± 4.62 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "y = fact_model(x)\n",
    "y[0].sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSEdibUbxhqi"
   },
   "source": [
    "# Prepare Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "a4c41d5f-4813-44d0-9630-d391b561221b"
   },
   "outputs": [],
   "source": [
    "# CIFAR10 Dataset\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    # Static constant variable\n",
    "    NUM_LABELS = 10\n",
    "\n",
    "    def __init__(self, data_split, *args, **kwargs):\n",
    "        self.data_split = data_split\n",
    "        if data_split == 'train':\n",
    "            transformations = transforms.Compose([\n",
    "                transforms.RandomCrop(32, padding=4),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.2435, 0.2616))\n",
    "            ])\n",
    "            self.dataset = CIFAR10('./cifar10', download=True, train=True, transform=transformations)\n",
    "            self.dataset.data = self.dataset.data[:-1000]\n",
    "            self.dataset.targets = self.dataset.targets[:-1000]\n",
    "        elif data_split == 'validation':\n",
    "            transformations = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.2435, 0.2616))])\n",
    "            self.dataset = CIFAR10('./cifar10', download=True, train=True, transform=transformations)\n",
    "            self.dataset.data = self.dataset.data[-1000:]\n",
    "            self.dataset.targets = self.dataset.targets[-1000:]\n",
    "        elif data_split == 'test':\n",
    "            transformations = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.2435, 0.2616))])\n",
    "            self.dataset = CIFAR10('./cifar10', download=True, train=False, transform=transformations)\n",
    "        else:\n",
    "            raise ValueError(f'Invalid dataset split: `{data_split}`')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.dataset[index]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNqpXY5BxL40",
    "outputId": "80e6e34f-1590-4ca6-bd29-f086922ad725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1b14cd6629468983fabda37f7a56c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset, test_dataset = CIFAR10Dataset('train'), CIFAR10Dataset('validation'), CIFAR10Dataset('test')\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, num_workers=8, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=256, num_workers=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsMHtW2n929K"
   },
   "source": [
    "# Run Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wQwGYT3G92BG"
   },
   "outputs": [],
   "source": [
    "# Forward function for image classification\n",
    "def forward_image_classification(model, batch_data, device='cpu', **kwargs):\n",
    "    # Unpack batch data\n",
    "    input_batch, label_batch = batch_data\n",
    "\n",
    "    # Prepare input & label\n",
    "    if device == \"cuda\":\n",
    "        input_batch = input_batch.cuda()\n",
    "        label_batch = label_batch.cuda()\n",
    "\n",
    "    # Forward model\n",
    "    outputs = model(input_batch, labels=label_batch)\n",
    "    loss, logits = outputs[:2]\n",
    "\n",
    "    # generate prediction & label list\n",
    "    list_hyp = []\n",
    "    list_label = []\n",
    "    hyp = torch.topk(logits, 1)[1]\n",
    "    for j in range(len(hyp)):\n",
    "        list_hyp.append(int(hyp[j].item()))\n",
    "        list_label.append(int(label_batch[j].item()))\n",
    "\n",
    "    return loss, list_hyp, list_label\n",
    "\n",
    "# Metric function for calculatting Accuracy and F1\n",
    "def acc_f1_metrics_fn(list_hyp, list_label):\n",
    "    metrics = {}\n",
    "    metrics[\"ACC\"] = accuracy_score(list_label, list_hyp)\n",
    "    metrics[\"F1\"] = f1_score(list_label, list_hyp, average='macro')\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kdfhIjgL-RmQ"
   },
   "outputs": [],
   "source": [
    "###\n",
    "# modelling functions\n",
    "###\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def metrics_to_string(metric_dict):\n",
    "    string_list = []\n",
    "    for key, value in metric_dict.items():\n",
    "        string_list.append('{}:{:.2f}'.format(key, value))\n",
    "    return ' '.join(string_list)\n",
    "\n",
    "###\n",
    "# Training & Evaluation Function\n",
    "###\n",
    "\n",
    "# Evaluate function for validation and test\n",
    "def evaluate(model, data_loader, forward_fn, metrics_fn, is_test=False, device='cpu'):\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    total_loss = 0\n",
    "    list_hyp, list_label = [], []\n",
    "\n",
    "    pbar = tqdm(iter(data_loader), leave=True, total=len(data_loader))\n",
    "    for i, batch_data in enumerate(pbar):\n",
    "        loss, batch_hyp, batch_label = forward_fn(model, batch_data, device=device)\n",
    "\n",
    "        # Calculate total loss\n",
    "        test_loss = loss.item()\n",
    "        total_loss = total_loss + test_loss\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        list_hyp += batch_hyp\n",
    "        list_label += batch_label\n",
    "        metrics = metrics_fn(list_hyp, list_label)\n",
    "\n",
    "        if not is_test:\n",
    "            pbar.set_description(\"VALID LOSS:{:.4f} {}\".format(total_loss/(i+1), metrics_to_string(metrics)))\n",
    "        else:\n",
    "            pbar.set_description(\"TEST LOSS:{:.4f} {}\".format(total_loss/(i+1), metrics_to_string(metrics)))\n",
    "\n",
    "    if is_test:\n",
    "        return total_loss, metrics, list_hyp, list_label\n",
    "    else:\n",
    "        return total_loss, metrics\n",
    "\n",
    "# Training function and trainer\n",
    "def train(model, train_loader, valid_loader, optimizer, forward_fn, metrics_fn, valid_criterion, n_epochs,\n",
    "              evaluate_every=1, early_stop=3, step_size=1, gamma=0.5, device=\"cpu\"):\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    best_val_metric = -100\n",
    "    count_stop = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        total_train_loss = 0\n",
    "        list_hyp, list_label = [], []\n",
    "\n",
    "        train_pbar = tqdm(iter(train_loader), leave=True, total=len(train_loader))\n",
    "        for i, batch_data in enumerate(train_pbar):\n",
    "            optimizer.zero_grad()\n",
    "            # Casts operations to mixed precision\n",
    "            with torch.cuda.amp.autocast():\n",
    "                loss, batch_hyp, batch_label = forward_fn(model, batch_data, device=device)\n",
    "\n",
    "                # Scales the loss, and calls backward() to create scaled gradients\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                # Unscales the gradients of optimizer's assigned params in-place\n",
    "                scaler.unscale_(optimizer)\n",
    "\n",
    "                # Since the gradients of optimizer's assigned params are unscaled, clips as usual:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 0.9)\n",
    "\n",
    "                # Unscales gradients and calls optimizer.step()\n",
    "                scaler.step(optimizer)\n",
    "\n",
    "                # Updates the scale for next iteration\n",
    "                scaler.update()\n",
    "\n",
    "            tr_loss = loss.item()\n",
    "            total_train_loss = total_train_loss + tr_loss\n",
    "\n",
    "            # Calculate metrics\n",
    "            list_hyp += batch_hyp\n",
    "            list_label += batch_label\n",
    "\n",
    "            train_pbar.set_description(\"(Epoch {}) TRAIN LOSS:{:.4f} LR:{:.8f}\".format((epoch+1),\n",
    "                total_train_loss/(i+1), get_lr(optimizer)))\n",
    "\n",
    "        metrics = metrics_fn(list_hyp, list_label)\n",
    "        print(\"(Epoch {}) TRAIN LOSS:{:.4f} {} LR:{:.8f}\".format((epoch+1),\n",
    "            total_train_loss/(i+1), metrics_to_string(metrics), get_lr(optimizer)))\n",
    "\n",
    "        # Decay Learning Rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # evaluate\n",
    "        if ((epoch+1) % evaluate_every) == 0:\n",
    "            val_loss, val_metrics = evaluate(model, valid_loader, forward_fn, metrics_fn, is_test=False, device=device)\n",
    "\n",
    "            # Early stopping\n",
    "            val_metric = val_metrics[valid_criterion]\n",
    "            if best_val_metric < val_metric:\n",
    "                best_val_metric = val_metric\n",
    "                torch.save(model.state_dict(), \"./best_model.th\")\n",
    "                count_stop = 0\n",
    "            else:\n",
    "                count_stop += 1\n",
    "                print(\"count stop:\", count_stop)\n",
    "                if count_stop == early_stop:\n",
    "                    break\n",
    "\n",
    "    # Return\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKiJLXUd-k5Z",
    "outputId": "77469fee-36d3-49e5-dc7f-0cf97e91a6c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 1) TRAIN LOSS:2.3872 LR:0.00100000:   1%|          | 1/192 [00:00<01:20,  2.38it/s]/tmp/ipykernel_12870/2653992668.py:78: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(model.parameters(), 0.9)\n",
      "(Epoch 1) TRAIN LOSS:1.0135 LR:0.00100000: 100%|████████| 192/192 [00:26<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1) TRAIN LOSS:1.0135 ACC:0.66 F1:0.66 LR:0.00100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID LOSS:0.6483 ACC:0.80 F1:0.79: 100%|███████████████████| 4/4 [00:00<00:00, 14.45it/s]\n",
      "(Epoch 2) TRAIN LOSS:0.6099 LR:0.00090000: 100%|████████| 192/192 [00:26<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2) TRAIN LOSS:0.6099 ACC:0.80 F1:0.80 LR:0.00090000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID LOSS:0.6325 ACC:0.80 F1:0.80: 100%|███████████████████| 4/4 [00:00<00:00, 12.40it/s]\n",
      "(Epoch 3) TRAIN LOSS:0.5011 LR:0.00081000: 100%|████████| 192/192 [00:26<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3) TRAIN LOSS:0.5011 ACC:0.83 F1:0.83 LR:0.00081000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID LOSS:0.5500 ACC:0.82 F1:0.82: 100%|███████████████████| 4/4 [00:00<00:00, 13.18it/s]\n",
      "(Epoch 4) TRAIN LOSS:0.4354 LR:0.00072900: 100%|████████| 192/192 [00:26<00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4) TRAIN LOSS:0.4354 ACC:0.85 F1:0.85 LR:0.00072900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID LOSS:0.4266 ACC:0.85 F1:0.84: 100%|███████████████████| 4/4 [00:00<00:00, 14.26it/s]\n",
      "(Epoch 5) TRAIN LOSS:0.3716 LR:0.00065610: 100%|████████| 192/192 [00:26<00:00,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 5) TRAIN LOSS:0.3716 ACC:0.87 F1:0.87 LR:0.00065610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID LOSS:0.4399 ACC:0.86 F1:0.86: 100%|███████████████████| 4/4 [00:00<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Phase ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST LOSS:0.4443 ACC:0.85 F1:0.85: 100%|██████████████████| 40/40 [00:02<00:00, 17.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACC': 0.8486, 'F1': 0.8493313984463514}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on Original model\n",
    "model = model.cuda()\n",
    "optimizer = AdamW(model.parameters(), lr=0.001)\n",
    "model = train(model, train_loader=train_loader, valid_loader=valid_loader, optimizer=optimizer, \n",
    "    forward_fn=forward_image_classification, metrics_fn=acc_f1_metrics_fn, valid_criterion='ACC', \n",
    "    n_epochs=5, evaluate_every=1, early_stop=3, step_size=1, gamma=0.9, device='cuda'\n",
    ")\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"./best_model.th\"))\n",
    "\n",
    "# Evaluation phase\n",
    "print('=== Evaluation Phase ===')\n",
    "test_loss, test_metrics, test_hyp, test_label = evaluate(model, data_loader=test_loader, \n",
    "        forward_fn=forward_image_classification, metrics_fn=acc_f1_metrics_fn, is_test=True, device='cuda')\n",
    "print(test_metrics)\n",
    "\n",
    "del optimizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 984
    },
    "id": "cD5DPsJFAF1_",
    "outputId": "ab953ca6-b290-4bd8-8657-d1259c322d86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Epoch 1) TRAIN LOSS:1.6294 LR:0.00100000: 100%|████████| 192/192 [00:28<00:00,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 1) TRAIN LOSS:1.6294 ACC:0.37 F1:0.37 LR:0.00100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID LOSS:1.1791 ACC:0.60 F1:0.59: 100%|███████████████████| 4/4 [00:00<00:00, 11.55it/s]\n",
      "(Epoch 2) TRAIN LOSS:0.8822 LR:0.00090000: 100%|████████| 192/192 [00:28<00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 2) TRAIN LOSS:0.8822 ACC:0.70 F1:0.70 LR:0.00090000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID LOSS:0.7820 ACC:0.74 F1:0.74: 100%|███████████████████| 4/4 [00:00<00:00, 11.42it/s]\n",
      "(Epoch 3) TRAIN LOSS:0.6562 LR:0.00081000: 100%|████████| 192/192 [00:28<00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 3) TRAIN LOSS:0.6562 ACC:0.78 F1:0.78 LR:0.00081000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID LOSS:0.6813 ACC:0.78 F1:0.77: 100%|███████████████████| 4/4 [00:00<00:00, 12.09it/s]\n",
      "(Epoch 4) TRAIN LOSS:0.5527 LR:0.00072900: 100%|████████| 192/192 [00:28<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 4) TRAIN LOSS:0.5527 ACC:0.82 F1:0.82 LR:0.00072900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID LOSS:0.5727 ACC:0.82 F1:0.81: 100%|███████████████████| 4/4 [00:00<00:00, 12.40it/s]\n",
      "(Epoch 5) TRAIN LOSS:0.4804 LR:0.00065610: 100%|████████| 192/192 [00:28<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 5) TRAIN LOSS:0.4804 ACC:0.84 F1:0.84 LR:0.00065610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID LOSS:0.4975 ACC:0.83 F1:0.83: 100%|███████████████████| 4/4 [00:00<00:00, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation Phase ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST LOSS:0.4961 ACC:0.83 F1:0.83: 100%|██████████████████| 40/40 [00:02<00:00, 14.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACC': 0.8281, 'F1': 0.8260633391714105}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on factorized model\n",
    "fact_model = fact_model.cuda()\n",
    "optimizer = AdamW(fact_model.parameters(), lr=0.001)\n",
    "fact_model = train(fact_model, train_loader=train_loader, valid_loader=valid_loader, optimizer=optimizer, \n",
    "    forward_fn=forward_image_classification, metrics_fn=acc_f1_metrics_fn, valid_criterion='ACC', \n",
    "    n_epochs=5, evaluate_every=1, early_stop=3, step_size=1, gamma=0.9, device='cuda'\n",
    ")\n",
    "\n",
    "# Load best model\n",
    "fact_model.load_state_dict(torch.load(\"./best_model.th\"))\n",
    "\n",
    "# Evaluation phase\n",
    "print('=== Evaluation Phase ===')\n",
    "test_loss, test_metrics, test_hyp, test_label = evaluate(fact_model, data_loader=test_loader, \n",
    "        forward_fn=forward_image_classification, metrics_fn=acc_f1_metrics_fn, is_test=True, device='cuda')\n",
    "print(test_metrics)\n",
    "\n",
    "del optimizer, fact_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rr3fVFTHBDwF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autofact_for_factorization_by_design.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_deep_fact",
   "language": "python",
   "name": "env_deep_fact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "factorize_vgg.ipynb",
   "output_path": "factorize_vgg.ipynb",
   "parameters": {},
   "start_time": "2021-08-19T03:10:38.168453",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
